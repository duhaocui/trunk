function varargout = updateintensity( this, sensor )

%p = particle('state',[-3555/2 3555/2 0 0],'weight',1,'label','p');
%nbp = particle('state',[3555/2 3555/2 0 0],'weight',1,'label','nb');
%this.predintensity = p;
%this.postintensity = [p,nbp];


Z = this.Z;

Zk_len = length(Z.Z);
P_D = this.probdetection;
lambda_c = sensor.clutter.getlambda;
meas.P_D = this.probdetection;
meas.clutterpdf = sensor.getclpdf(Z.Z);%1/(pi*sensor.maxrange^2);
flt_param.N_max = length( this.postcard )-1;
flt_param.rho = this.numpartpersist;
flt_param.Lmax = this.maxnumpart;
cdn_pred = this.predcard;

if isempty( this.predintensity )
   if nargout == 0
        if ~isempty( inputname(1) )
            assignin('caller',inputname(1),this);
        else
            error('Could not overwrite the instance; make sure that the argument is not in an array!');
        end
    else
        varargout{1} = this;
    end
    return;
end

% Get the particles regarding the loc. dist. of the predicted intensity
w_pred = this.predintensity.s.particles.getweights...
    *this.predintensity.mu ;
p = this.predintensity.s.particles.getstates;


if isfield( sensor, 'pdprofile' )
    P_D = sensor.pdprofile.getpdprofile( sqrt(sum(p([1,2],:).*p([1,2],:),1 )) );
else
    P_D = ones( length(w_pred), 1)*sensor.pd;
end
P_D = P_D(:);

% Liklihood function matrix
Gk = sensor.likelihood( Z, p );



% Elementary symmetric functions
intpdgv = zeros(Zk_len,1);
for i=1:Zk_len
    intpdgv(i) = sum( P_D.*Gk(i,:)'.*w_pred ); % + Gkn(i,:)*w_nb;
end
zvals = intpdgv./meas.clutterpdf ;
esfvals = sumesf(zvals);
% Elementary symmetric functions for removed observations
esfvals_D = zeros(Zk_len,Zk_len);
for i=1:Zk_len
    esfvals_D(:,i) = sumesf([zvals(1:i-1);zvals(i+1:Zk_len)]);
end
% cardinality of clutter
cdn_K = poisspdf([0:max(flt_param.N_max,Zk_len)],lambda_c);
% predicted number of objects (integral of pred PHD)

% Computation of Upsilon 0 and 1
Ups0 = zeros(flt_param.N_max+1,1);
Ups1 = zeros(flt_param.N_max+1,1);
nu_pred = sum(w_pred);
fapred = sum( w_pred.*(1 - P_D ) );

% Get new born particle weights
if ~isempty( this.nbintensity )
    nu_nb  = this.nbintensity.mu;
else
    nu_nb  = 0;
end

for n=0:flt_param.N_max
    for j=0:min(Zk_len,n)
        Pnj0 = this.Pcoef( n+1,j+1 ) ;%permcoeff( n, j ); % prod([n-j+1:n]);
        Pnj1 = this.Pcoef( n+1,j+1 + 1 ); %permcoeff( n, j + 1 ); %prod([n-(j+1)+1:n]);
        
        if Zk_len-j > length( this.factor );
            facterm = factorial(Zk_len-j) ;
        else
            facterm = this.factor( Zk_len - j + 1);
        end
        Ups0(n+1) = Ups0(n+1)+ facterm * cdn_K(Zk_len-j+1) * ...
            Pnj0 *( fapred^(n-j) /(nu_pred+nu_nb)^n) ...
            * esfvals(j+1);
        
        Ups1(n+1) = Ups1(n+1)+ facterm * cdn_K(Zk_len-j+1) * ...
            Pnj1 * ( fapred^(n-j-1)/(nu_pred+nu_nb)^n) ...
            * esfvals(j+1); 
    end
end
% Computation of Ups 1 for removed obs
Ups1_D = zeros(flt_param.N_max+1,Zk_len);
for i=1:Zk_len
    for n=0:flt_param.N_max
        for j=0:min(Zk_len-1,n)
            Pnj1 = this.Pcoef( n+1,j+1  + 1 ); %permcoeff( n, j + 1 ); %prod([n-(j+1)+1:n]);
            
            if Zk_len-j-1 > length( this.factor );
                facterm = factorial(Zk_len-j -1 ) ;
            else
                facterm = this.factor( Zk_len - j -1 + 1);
            end
            Ups1_D(n+1,i) = Ups1_D(n+1,i)+ facterm * cdn_K(Zk_len-1-j+1)* ...
                Pnj1 * ( fapred^(n-j-1)/(nu_pred+nu_nb)^n) ...
                * esfvals_D(j+1,i);
            
        end
    end
end

% Updated cardinality
cdn_pred = (cdn_pred + 1e-20)/(sum(cdn_pred + 1e-20));
denom = sum(Ups0 .* cdn_pred);
cdn = Ups0 .* cdn_pred / denom;

%Updated weights and particles
w_upd_comp = zeros(length(w_pred),Zk_len+1);

for i=1:Zk_len
    w_upd_comp(:,i) = P_D.*Gk(i,:)'.*w_pred* (sum(Ups1_D(:,i).*cdn_pred)/denom)/meas.clutterpdf(i);
end

w_upd_comp(:,Zk_len+1) =  w_pred .* (1-P_D)* sum(Ups1 .* cdn_pred) / denom;

% MU:
% Here we sort the contribution of each measurement to each particle and
% achieve a clustering:
[maxCont, clusterIndx] = max( w_upd_comp(:,1:Zk_len+1)' );
clusterIndx( find(clusterIndx==Zk_len+1 ) )=0;

w_upd = sum(w_upd_comp,2)';

% resampling
hat_N_soft = sum(w_upd);
if hat_N_soft> 0.05, %resamplingUpdatePersistent2.m
    persupdate = this.predintensity.s.particles;
    persupdate = persupdate.sublabels( clusterIndx );
    persupdate = persupdate.subweights( w_upd/hat_N_soft );
    
    
    if this.regflag
        % persupdate = persupdate.updatekdebws('nonsparse','dims','all'); % Here, the BWs are found
        % NOTE: If the velocity components are generated by a mixture by the
        % adaptive new born target process, then the dims above should be
        % [1,2]'
     %   if this.veldist.getnumcomp==1
            persupdate = persupdate.updatekdebwsblabh('nonsparse'); % Here, the BWs are found
      %  else
      %      persupdate = persupdate.updatekdebws('nonsparse','dims',[1,2]'); % Here, the BWs are found
      %  end
    end
    
    % Resample 
    Lk= min(round(hat_N_soft*flt_param.rho),flt_param.Lmax);
    [persupdate, resindx] = persupdate.resample(Lk);
   
    if this.regflag
        persupdate = persupdate.regwkde(this.regvar);
    end
   
    
    
    persupdate = persupdate.inchist; % increase the history length by one
    
    this.postintensity = phd;
    this.postintensity.mu = hat_N_soft;
    
    this.postintensity.s.particles = persupdate;
    this.postintensity.s.kdes = [];
    this.postintensity.s.gmm = [];
    this.resindx = resindx;
    this.postcard  =cdn;
else
   % this.postintensity = this.predintensity;
   % this.postcard  =cdn;
end



if nargout == 0
    if ~isempty( inputname(1) )
        assignin('caller',inputname(1),this);
    else
        error('Could not overwrite the instance; make sure that the argument is not in an array!');
    end
else
    varargout{1} = this;
end